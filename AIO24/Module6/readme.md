# Module 6

## **Overview**
Module 6 of the **AIO24** course advances into the realm of deep learning architectures, particularly focusing on models that excel in image and sequence processing. Learners will explore advanced convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformer-based architectures such as Vision Transformers (ViT), gaining hands-on experience with real-world applications.

## **Topics Covered**

### **1. Convolutional Neural Networks (CNNs)**
- Deep CNN architectures for complex image classification tasks.
- Techniques Covered:
  - Data augmentation
  - Batch normalization
  - Dropout

### **2. Recurrent Neural Networks (RNNs)**
- Designed for sequential data such as time series or language.
- Topics Covered:
  - Vanilla RNNs
  - Long Short-Term Memory (LSTM)
  - Gated Recurrent Units (GRU)

### **3. Transformer**
- Transformer architecture for handling sequence data in parallel.
- Key Concepts:
  - Self-attention mechanism
  - Positional encoding
  - Encoder-decoder structure

## **Projects**
- Visual Question Answering (VQA): https://github.com/qhung23125005/Visual-Question-Answering
- Scene Text Detection (OCR): https://github.com/qhung23125005/Scene-Text-Detection
