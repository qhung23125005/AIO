{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will adpot the UNet in Ex1 for Super Resolution problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torcheval.metrics.functional import peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is downloaded manually on Kaggle https://www.kaggle.com/datasets/adityachandrasekhar/image-super-resolution?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "\n",
    "print(\"Current working directory: {0}\".format(current_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# Unzip the data\n",
    "with ZipFile(os.path.join(current_path, 'ImageSuperResolution.zip'), 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_IMG_SIZE = 64\n",
    "HIGH_IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "low_res = os.path.join(current_path, 'dataset/train/low_res/0.png')\n",
    "high_res = os.path.join(current_path, 'dataset/train/high_res/0.png')\n",
    "\n",
    "\n",
    "low_res_img = np.array(Image.open(low_res).resize((LOW_IMG_SIZE, LOW_IMG_SIZE))).astype(np.int32)\n",
    "high_res_img = np.array(Image.open(high_res).resize((HIGH_IMG_SIZE, HIGH_IMG_SIZE))).astype(np.int32)\n",
    "plt.imshow(low_res_img)\n",
    "plt.title('Low Resolution Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(high_res_img)\n",
    "plt.title('High Resolution Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f'Low Resolution Image Shape: {low_res_img.shape}')\n",
    "print(f'High Resolution Image Shape: {high_res_img.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, is_train=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.is_train = is_train\n",
    "        self.input_images = os.listdir(os.path.join(img_dir, 'low_res'))\n",
    "        self.target_images = os.listdir(os.path.join(img_dir, 'high_res'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image * 2 - 1\n",
    "        return image\n",
    "    \n",
    "    def random_jitter ( self , input_image , target_image ) :\n",
    "        if torch.rand ([]) < 0.5:\n",
    "            input_image = transforms . functional . hflip ( input_image )\n",
    "            target_image = transforms . functional . hflip ( target_image )\n",
    "\n",
    "        return input_image , target_image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_path = os.path.join(self.img_dir, 'low_res', self.input_images[idx])\n",
    "        target_path = os.path.join(self.img_dir, 'high_res', self.target_images[idx])\n",
    "        \n",
    "        input_image = np.array(Image.open(input_path).convert(\"RGB\"))\n",
    "        target_image = np.array(Image.open(target_path).convert(\"RGB\"))\n",
    "        input_image = transforms.ToTensor()(input_image).type(torch.float32)\n",
    "        target_image = transforms.ToTensor()(target_image).type(torch.float32)\n",
    "\n",
    "        input_image = self.normalize(input_image)\n",
    "        target_image = self.normalize(target_image)\n",
    "    \n",
    "\n",
    "        if self.is_train:\n",
    "            input_image, target_image = self.random_jitter(input_image, target_image)\n",
    "        \n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(os.path.join(current_path, 'dataset/train'), is_train = True)\n",
    "val_dataset = ImageDataset(os.path.join(current_path, 'dataset/val'), is_train= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstFeature(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FirstFeature, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.conv(x)\n",
    "        x = torch.concat([x, skip], dim=1)\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalOutput(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FinalOutput, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_channels=3, n_classes=3\n",
    "    ):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.resize_fnc = transforms.Resize((LOW_IMG_SIZE*4, LOW_IMG_SIZE*4),\n",
    "                                             antialias=True)\n",
    "        self.in_conv1 = FirstFeature(n_channels, 64)\n",
    "        self.in_conv2 = ConvBlock(64, 64)\n",
    "\n",
    "        self.enc_1 = Encoder(64, 128)\n",
    "        self.enc_2 = Encoder(128, 256)\n",
    "        self.enc_3 = Encoder(256, 512)\n",
    "        self.enc_4 = Encoder(512, 1024)\n",
    "\n",
    "        self.dec_1 = Decoder(1024, 512)\n",
    "        self.dec_2 = Decoder(512, 256)\n",
    "        self.dec_3 = Decoder(256, 128)\n",
    "        self.dec_4 = Decoder(128, 64)\n",
    "\n",
    "        self.out_conv = FinalOutput(64, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resize_fnc(x)\n",
    "        x = self.in_conv1(x)\n",
    "        x1 = self.in_conv2(x)\n",
    "\n",
    "        x2 = self.enc_1(x1)\n",
    "        x3 = self.enc_2(x2)\n",
    "        x4 = self.enc_3(x3)\n",
    "        x5 = self.enc_4(x4)\n",
    "\n",
    "        x = self.dec_1(x5, x4)\n",
    "        x = self.dec_2(x, x3)\n",
    "        x = self.dec_3(x, x2)\n",
    "        x = self.dec_4(x, x1)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_dataloader, device, epoch=0,\n",
    "                log_interval=50):\n",
    "    model.train()\n",
    "    total_psnr, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_psnr += peak_signal_noise_ratio(predictions, labels)\n",
    "        total_count += 1\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| psnr {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_loader), total_psnr / total_count\n",
    "                )\n",
    "            )\n",
    "            total_psnr, total_count = 0, 0\n",
    "\n",
    "    epoch_psnr = total_psnr / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_psnr, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, criterion, valid_dataloader, device):\n",
    "    model.eval()\n",
    "    total_psnr, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "            total_psnr +=  peak_signal_noise_ratio(predictions, labels)\n",
    "            total_count += 1\n",
    "\n",
    "    epoch_psnr = total_psnr / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_psnr, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device):\n",
    "    train_psnrs, train_losses = [], []\n",
    "    eval_psnrs, eval_losses = [], []\n",
    "    best_psnr_eval = -1000\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # Training\n",
    "        train_psnr, train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device, epoch)\n",
    "        train_psnrs.append(train_psnr.cpu())\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluation\n",
    "        eval_psnr, eval_loss = evaluate_epoch(model, criterion, valid_dataloader, device)\n",
    "        eval_psnrs.append(eval_psnr.cpu())\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if best_psnr_eval < eval_psnr :\n",
    "            torch.save(model.state_dict(), save_model + f'/{model_name}.pt')\n",
    "            best_psnr_eval = eval_psnr\n",
    "        # Print loss, psnr end epoch\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| End of epoch {:3d} | Train psnr {:8.3f} | Train Loss {:8.3f} \"\n",
    "            \"| Valid psnr {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "                epoch, train_psnr, train_loss, eval_psnr, eval_loss\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
    "    model.eval()\n",
    "    metrics = {\n",
    "        'train_psnr': train_psnrs,\n",
    "        'train_loss': train_losses,\n",
    "        'valid_psnr': eval_psnrs,\n",
    "        'valid_loss': eval_losses,\n",
    "    }\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "unet = UNet(n_channels=3, n_classes=3).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(unet.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "num_epochs = 75\n",
    "model_name = 'super_resolution'\n",
    "save_model = os.path.join(current_path, 'models')\n",
    "if not os.path.exists(save_model):\n",
    "    os.makedirs(save_model)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model, metrics = train(unet, model_name, save_model, optimizer, criterion, train_loader, val_loader, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ax[0].plot(metrics['train_psnr'], label='Train PSNR')\n",
    "ax[0].plot(metrics['valid_psnr'], label='Validation PSNR')\n",
    "ax[0].set_title('PSNR')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('PSNR')\n",
    "ax[0].legend()\n",
    "ax[1].plot(metrics['train_loss'], label='Train Loss')\n",
    "ax[1].plot(metrics['valid_loss'], label='Validation Loss')\n",
    "ax[1].set_title('Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "imgs = os.listdir(os.path.join(current_path, 'dataset/val/low_res'))\n",
    "model = UNet(n_channels=3, n_classes=3).to(device)\n",
    "model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Process and display the first 5 images\n",
    "for img in imgs[:5]:\n",
    "    input_path = os.path.join(current_path, \"dataset/val/low_res\", img)\n",
    "    input_image = Image.open(input_path).convert(\"RGB\")\n",
    "    input_tensor = np.array(input_image)\n",
    "    input_tensor = transforms.ToTensor()(input_tensor).type(torch.float32)\n",
    "    # Apply transformations\n",
    "    input_tensor = 2 * input_tensor - 1  # Normalize to [-1, 1]\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    output = output.cpu().squeeze(0).detach().numpy().transpose(1, 2, 0)\n",
    "    output = Image.fromarray(((output + 1) * 127.5).astype(np.uint8))\n",
    "    \n",
    "    # Post-process the output\n",
    "\n",
    "\n",
    "    #output_image = transforms.ToPILImage()(output)  # Convert tensor to PIL image\n",
    "\n",
    "    # Denormalize the input tensor before displaying\n",
    "    #input_tensor = denormalize(input_tensor)  # Fix colors\n",
    "\n",
    "    # Display images side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(input_image)\n",
    "    axes[0].set_title(\"Input Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(output)\n",
    "    axes[1].set_title(\"Super-Resolved Output\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
