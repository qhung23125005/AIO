{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will address Machine translation task by utilizing Neural networks. We will compare the performance of RNN and Transformer for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tokenizers import Tokenizer, pre_tokenizers, trainers, models\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('thainq107/iwslt2015-en-vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133317\n",
      "1268\n",
      "1268\n",
      "{'en': 'Rachel Pike : The science behind a climate headline', 'vi': 'Khoa học đằng sau một tiêu đề về khí hậu'}\n",
      "{'en': 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .', 'vi': 'Trong 4 phút , chuyên gia hoá học khí quyển Rachel Pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .'}\n"
     ]
    }
   ],
   "source": [
    "print(len(ds['train']))\n",
    "print(len(ds['validation']))\n",
    "print(len(ds['test']))\n",
    "print(ds['train'][0])\n",
    "print(ds['train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
    "tokenizer_vi = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
    "\n",
    "tokenizer_en.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "tokenizer_vi.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "trainer = trainers.WordLevelTrainer(\n",
    "    vocab_size=15000,\n",
    "    special_tokens=[\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"],\n",
    "    min_frequency=2,\n",
    ")\n",
    "\n",
    "tokenizer_en.train_from_iterator(ds['train']['en'], trainer=trainer)\n",
    "tokenizer_vi.train_from_iterator(ds['train']['vi'], trainer=trainer)\n",
    "\n",
    "tokenizer_en.save(\"tokenizer_en.json\")\n",
    "tokenizer_vi.save(\"tokenizer_vi.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88f332fd1b74347afe954bfedb088dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 75\n",
    "\n",
    "tokenizer_en = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"tokenizer_en.json\",\n",
    "    bos_token=\"<bos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    unk_token=\"<unk>\",\n",
    ")\n",
    "\n",
    "tokenizer_vi = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"tokenizer_vi.json\",\n",
    "    bos_token=\"<bos>\",\n",
    "    eos_token=\"<eos>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    unk_token=\"<unk>\",\n",
    ")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    src_texts = examples [\"en\"]\n",
    "    tgt_texts = [\"<bos> \" + sent + \"<eos>\" for sent in examples [\"vi\"]]\n",
    "\n",
    "    src_encodings = tokenizer_en(src_texts, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "    tgt_encodings = tokenizer_vi(tgt_texts, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "\n",
    "    return {\n",
    "        'input_ids': src_encodings['input_ids'],\n",
    "        'labels': tgt_encodings['input_ids'],\n",
    "    }\n",
    "\n",
    "preprocessed_ds = ds.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Rachel Pike : The science behind a climate headline', 'vi': 'Khoa học đằng sau một tiêu đề về khí hậu', 'input_ids': [6675, 1, 57, 60, 339, 604, 13, 744, 5643, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [2, 1960, 66, 1157, 131, 8, 376, 113, 38, 417, 735, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_ds['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNNConfig(PretrainedConfig):\n",
    "    def __init__(self, \n",
    "                 vocab_size_src=10000, \n",
    "                 vocab_size_tgt=10000,\n",
    "                 embedding_dim=128,\n",
    "                 hidden_size=128,\n",
    "                 dropout=0.1,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vocab_size_src = vocab_size_src\n",
    "        self.vocab_size_tgt = vocab_size_tgt\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, dropout_p =0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x)) # (batch_size, seq_len, embedding_dim)\n",
    "        output, hidden = self.gru(embedded) # (batch_size, seq_len, hidden_size), (batch_size, hidden_size)\n",
    "        return output, hidden\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(PreTrainedModel):\n",
    "    config_class = Seq2SeqRNNConfig\n",
    "\n",
    "    def __init__(self, config, tokenizer_en):\n",
    "        super(Seq2SeqRNN, self).__init__(config)\n",
    "        self.encoder = EncoderRNN(config.vocab_size_src, config.embedding_dim, config.hidden_size, config.dropout)\n",
    "        self.decoder = DecoderRNN(config.hidden_size, config.embedding_dim, config.vocab_size_tgt)\n",
    "        self.BOS_IDX = tokenizer_en.bos_token_id\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.pad_token_id)\n",
    "\n",
    "    def forward(self, input_ids, labels):\n",
    "        # Mask for the decoder input\n",
    "        batch_size, seq_len = labels.shape\n",
    "        decoder_input = torch.full((batch_size, 1), self.BOS_IDX, dtype=torch.long).to(input_ids.device)\n",
    "        encoder_output, decoder_hidden = self.encoder(input_ids)\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            decoder_input = labels[:, i].unsqueeze(1)\n",
    "\n",
    "        logits = torch.cat(decoder_outputs, dim=1)\n",
    "        loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz, device):\n",
    "    \"\"\"Generate a square mask for the sequence.\"\"\"\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    return mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "    device = src.device\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device).to(torch.bool)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "    src_padding_mask = (src == 0)\n",
    "    tgt_padding_mask = (tgt == 0)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SegTransformerConfig(PretrainedConfig):\n",
    "    def __init__(self, \n",
    "                 vocab_size_src=10000, \n",
    "                 vocab_size_tgt=10000,\n",
    "                 d_model=128,\n",
    "                 n_heads=4,\n",
    "                 n_layers=3,\n",
    "                 dropout=0.1,\n",
    "                 max_seq_len=75,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vocab_size_src = vocab_size_src\n",
    "        self.vocab_size_tgt = vocab_size_tgt\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "\n",
    "class Seq2SeqTransformer(PreTrainedModel):\n",
    "    config_class = Seq2SegTransformerConfig\n",
    "\n",
    "    def __init__(self, config, tokenizer_en):\n",
    "        super(Seq2SeqTransformer, self).__init__(config)\n",
    "        self.embedding_src = nn.Embedding(config.vocab_size_src, config.d_model)\n",
    "        self.embedding_tgt = nn.Embedding(config.vocab_size_tgt, config.d_model)\n",
    "\n",
    "        self.positional_encoding_src = nn.Embedding(config.max_seq_len, config.d_model)\n",
    "        self.positional_encoding_tgt = nn.Embedding(config.max_seq_len, config.d_model)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=config.d_model,\n",
    "            nhead=config.n_heads,\n",
    "            num_encoder_layers=config.n_layers,\n",
    "            num_decoder_layers=config.n_layers,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.generator = nn.Linear(config.d_model, config.vocab_size_tgt)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.pad_token_id)\n",
    "\n",
    "    def forward(self, input_ids, labels):\n",
    "        tgt_input = labels[:, :-1] \n",
    "        tgt_output = labels[:, 1:] \n",
    "        batch_size, src_seq_len = input_ids.shape\n",
    "        _, tgt_seq_len = tgt_input.shape\n",
    "\n",
    "        src_pos = torch.arange(src_seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        tgt_pos = torch.arange(tgt_seq_len, device=labels.device).unsqueeze(0)\n",
    "\n",
    "        src_positional_encoding = self.positional_encoding_src(src_pos)\n",
    "        tgt_positional_encoding = self.positional_encoding_tgt(tgt_pos)\n",
    "\n",
    "        src_embedding = self.embedding_src(input_ids) + src_positional_encoding\n",
    "        tgt_embedding = self.embedding_tgt(tgt_input) + tgt_positional_encoding\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(input_ids, tgt_input)\n",
    "        transformer_output = self.transformer(\n",
    "            src_embedding, tgt_embedding, src_mask, tgt_mask,\n",
    "            src_key_padding_mask=src_padding_mask, \n",
    "            tgt_key_padding_mask=tgt_padding_mask, \n",
    "        )\n",
    "\n",
    "        logits = self.generator(transformer_output)\n",
    "        loss = self.loss_fn(logits.permute(0, 2, 1), tgt_output)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits,\n",
    "        }\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        _, src_seq_len = src.shape\n",
    "        src_pos = torch.arange(src_seq_len, device=src.device).unsqueeze(0)\n",
    "        src_positional_encoding = self.positional_encoding_src(src_pos)\n",
    "        src_embedding = self.embedding_src(src) + src_positional_encoding\n",
    "        return self.transformer.encoder(src_embedding, src_mask)\n",
    "    \n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        _, tgt_seq_len = tgt.shape\n",
    "        tgt_pos = torch.arange(tgt_seq_len, device=tgt.device).unsqueeze(0)\n",
    "        tgt_positional_encoding = self.positional_encoding_tgt(tgt_pos)\n",
    "        tgt_embedding = self.embedding_tgt(tgt) + tgt_positional_encoding\n",
    "        return self.transformer.decoder(tgt_embedding, memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model\n",
    "config_rnn = Seq2SeqRNNConfig(\n",
    "    vocab_size_src=tokenizer_en.vocab_size,\n",
    "    vocab_size_tgt=tokenizer_vi.vocab_size,\n",
    ")\n",
    "\n",
    "model_rnn = Seq2SeqRNN(config_rnn, tokenizer_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6525' max='6525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6525/6525 16:33, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.401700</td>\n",
       "      <td>9.247737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.811200</td>\n",
       "      <td>7.891889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.193600</td>\n",
       "      <td>6.775835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.559200</td>\n",
       "      <td>6.415434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.306800</td>\n",
       "      <td>6.243595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.177600</td>\n",
       "      <td>6.147282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.101500</td>\n",
       "      <td>6.087337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.053000</td>\n",
       "      <td>6.047566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.018900</td>\n",
       "      <td>6.018620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.992100</td>\n",
       "      <td>5.995044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.969800</td>\n",
       "      <td>5.974766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.950300</td>\n",
       "      <td>5.956898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.932900</td>\n",
       "      <td>5.940750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.917200</td>\n",
       "      <td>5.925632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.902200</td>\n",
       "      <td>5.911424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.887800</td>\n",
       "      <td>5.897529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.874000</td>\n",
       "      <td>5.884593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.861600</td>\n",
       "      <td>5.872684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>5.862019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.839700</td>\n",
       "      <td>5.852852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.831100</td>\n",
       "      <td>5.845237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.824300</td>\n",
       "      <td>5.839237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.819000</td>\n",
       "      <td>5.834920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.815700</td>\n",
       "      <td>5.832315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.813600</td>\n",
       "      <td>5.831439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6525, training_loss=6.268184117576628, metrics={'train_runtime': 994.0597, 'train_samples_per_second': 3352.842, 'train_steps_per_second': 6.564, 'total_flos': 2944709228925000.0, 'train_loss': 6.268184117576628, 'epoch': 25.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rnn-en-vi-machine-translation\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    num_train_epochs=25,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer_rnn = Trainer(\n",
    "    model=model_rnn,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_ds['train'],\n",
    "    eval_dataset=preprocessed_ds['validation'],\n",
    ")\n",
    "\n",
    "trainer_rnn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model\n",
    "config_transformer = Seq2SegTransformerConfig(\n",
    "    vocab_size_src=tokenizer_en.vocab_size,\n",
    "    vocab_size_tgt=tokenizer_vi.vocab_size,\n",
    ")\n",
    "model_transformer = Seq2SeqTransformer(config_transformer, tokenizer_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6525' max='6525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6525/6525 47:12, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.672600</td>\n",
       "      <td>8.044556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.649100</td>\n",
       "      <td>7.210210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.965700</td>\n",
       "      <td>6.677534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.538300</td>\n",
       "      <td>6.345466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.267700</td>\n",
       "      <td>6.131791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.086500</td>\n",
       "      <td>5.978821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.952400</td>\n",
       "      <td>5.862052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.846500</td>\n",
       "      <td>5.767285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.757600</td>\n",
       "      <td>5.685838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.680300</td>\n",
       "      <td>5.614264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.612300</td>\n",
       "      <td>5.551495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.552000</td>\n",
       "      <td>5.495063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.498100</td>\n",
       "      <td>5.444248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.450700</td>\n",
       "      <td>5.400600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.408200</td>\n",
       "      <td>5.361367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.371000</td>\n",
       "      <td>5.327089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.338200</td>\n",
       "      <td>5.296885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.310600</td>\n",
       "      <td>5.271691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.286500</td>\n",
       "      <td>5.250029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.266100</td>\n",
       "      <td>5.232523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.249300</td>\n",
       "      <td>5.217495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.236300</td>\n",
       "      <td>5.206576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.226500</td>\n",
       "      <td>5.198547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.220100</td>\n",
       "      <td>5.193759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.216500</td>\n",
       "      <td>5.192132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6525, training_loss=5.826371808399186, metrics={'train_runtime': 2833.7907, 'train_samples_per_second': 1176.137, 'train_steps_per_second': 2.303, 'total_flos': 8283191184765000.0, 'train_loss': 5.826371808399186, 'epoch': 25.0})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./transformer-en-vi-machine-translation\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    num_train_epochs=25,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer_transformer = Trainer(\n",
    "    model=model_transformer,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_ds['train'],\n",
    "    eval_dataset=preprocessed_ds['validation'],\n",
    ")\n",
    "\n",
    "trainer_transformer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  i\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m sentence = \u001b[33m'\u001b[39m\u001b[33mi\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInput: \u001b[39m\u001b[33m\"\u001b[39m, sentence)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredicted: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_transformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtranslate\u001b[39m\u001b[34m(model, src_sentence, device)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranslate\u001b[39m(model, src_sentence, device):\n\u001b[32m     23\u001b[39m     model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     input_ids = \u001b[43mtokenizer_en\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msrc_sentence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     num_tokens = input_ids.shape[\u001b[32m1\u001b[39m]\n\u001b[32m     26\u001b[39m     src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(device)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol, device=\"cpu\"):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(1), device)\n",
    "                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        prob = model.generator(out[:, -1, :]) # LM Head\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word[-1].item() # index\n",
    "\n",
    "        ys = torch.cat([ys,torch.ones(1, 1).type_as(\n",
    "            src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == 3: #EOS : 3\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model, src_sentence, device):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer_en([src_sentence], return_tensors='pt')['input_ids'].to(device)\n",
    "    num_tokens = input_ids.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(device)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  input_ids, src_mask, max_len=num_tokens + 5, start_symbol=2, device=device)\n",
    "    return tokenizer_vi.decode(tgt_tokens.detach().cpu()[0])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentence = 'i'\n",
    "print(\"Input: \", sentence)\n",
    "print(\"Predicted: \", translate(model_transformer, sentence, device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
