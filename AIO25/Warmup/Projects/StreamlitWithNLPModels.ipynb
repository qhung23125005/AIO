{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qhung23125005/AIO/blob/main/StreamlitWithNLPModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7VSmcEW_Je-"
      },
      "source": [
        "#Setup Streamlit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QrihyKbR--mT"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit==1.41.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVZ5Rstf_aVy",
        "outputId": "be6710c5-648c-4f5a-e1a1-8e2b34aabab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.35.179"
          ]
        }
      ],
      "source": [
        "#Get password\n",
        "!wget -q -O - https://loca.lt/mytunnelpassword\n",
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa_lVvxtAJyY",
        "outputId": "1e11ebf8-0da9-49e2-d44f-d284f5225acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demo.py\n"
          ]
        }
      ],
      "source": [
        "#prepare file demo.py\n",
        "%%writefile demo.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"My Project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ3DHu_JBZYM",
        "outputId": "9347aa40-0d81-4ee7-d7e4-b9961d552423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.219.210:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0Kyour url is: https://curvy-falcons-grin.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Run streamlit through port 8501\n",
        "!streamlit run demo.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMzJ7SHeJ8_1"
      },
      "source": [
        "#Basic Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrlrweqHK5pT",
        "outputId": "262fe7e3-eeb3-4c1d-f163-0f971c1c90cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZF09wOx9IxUEuZ2iFdQHOp3udYHCm1-Y\n",
            "To: /content/ChiPu.jpg\n",
            "\r  0% 0.00/129k [00:00<?, ?B/s]\r100% 129k/129k [00:00<00:00, 17.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1ZF09wOx9IxUEuZ2iFdQHOp3udYHCm1-Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krsMq90ASaBq"
      },
      "source": [
        "##Implement the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLjUiWngKBld",
        "outputId": "42ebf94b-af13-4b25-b2bf-6d2717e39a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "# Text elements\n",
        "st.title(\"MY PROJECT\")\n",
        "st.header(\"This is a header\")\n",
        "st.subheader(\"This is a subheader\")\n",
        "st.caption(\"This is a caption\")\n",
        "st.text(\"This is a text\")\n",
        "\n",
        "# Display string formatted as Markdown\n",
        "st.divider()\n",
        "\n",
        "st.markdown(\"# Heading 1\")\n",
        "st.markdown(\"\"\"\n",
        "    1. Machine Learning\n",
        "    2. Deep Learning\"\"\")\n",
        "st.markdown(r\"$\\sqrt{2x+2}$\")\n",
        "\n",
        "# Display mathematical expressions formatted as LaTeX\n",
        "st.divider()\n",
        "\n",
        "st.latex(r\"\\sqrt{2x+2}\")\n",
        "\n",
        "# Display a code block with optional syntax highlighting\n",
        "st.divider()\n",
        "\n",
        "st.code(\"\"\"\n",
        "    import torch\n",
        "    data = torch.Tensor([1, 2, 3])\n",
        "    print(data)\n",
        "\"\"\", language=\"python\")\n",
        "\n",
        "# Write arguments to the app\n",
        "st.divider()\n",
        "\n",
        "st.write('## Heading 2')\n",
        "st.write(r'$ \\sqrt{2x+2} $')\n",
        "st.write('1 + 1 = ', 2)\n",
        "\n",
        "# Echo: Use in a with block to draw some code on the app, then execute it\n",
        "st.divider()\n",
        "\n",
        "def get_user_name():\n",
        "    return 'Hung'\n",
        "with st.echo():\n",
        "    st.write('This code will be printed')\n",
        "    def get_email():\n",
        "        return 'xqhung23@apcs.fitus.edu.vn'\n",
        "    user_name = get_user_name()\n",
        "    email = get_email()\n",
        "    st.write(user_name, email)\n",
        "\n",
        "# Media elements\n",
        "# Display an image/audio/video/logo\n",
        "st.divider()\n",
        "\n",
        "st.image(\n",
        "    './ChiPu.jpg',\n",
        "    caption='Theme.'\n",
        ")\n",
        "# st.audio('./audio.mp4')\n",
        "# st.video('./video.mp4')\n",
        "\n",
        "# Input widgets\n",
        "st.divider()\n",
        "\n",
        "title = st.text_input(\"Movie title\", \"Chi chi em em\")\n",
        "st.write(\"The current movie title is\", title)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "def get_name():\n",
        "    st.write(\"Hung\")\n",
        "agree = st.checkbox(\"I agree\", on_change=get_name)\n",
        "if agree:\n",
        "    st.write(\"Great!\")\n",
        "\n",
        "st.radio(\n",
        "    \"Your favorite color:\",\n",
        "    ['Yellow', 'Blue'],\n",
        "    captions = ['Vàng', 'Xanh']\n",
        ")\n",
        "\n",
        "option = st.selectbox(\n",
        "    \"Your contact:\",\n",
        "    (\"Email\", \"Home phone\", \"Mobile phone\"))\n",
        "\n",
        "st.write(\"Selected:\", option)\n",
        "\n",
        "options = st.multiselect(\n",
        "    \"Your favorite colors:\",\n",
        "    [\"Green\", \"Yellow\", \"Red\", \"Blue\"],\n",
        "    [\"Yellow\", \"Red\"])\n",
        "\n",
        "st.write(\"You selected:\", options)\n",
        "\n",
        "color = st.select_slider(\n",
        "    \"Your favorite color:\",\n",
        "    options=[\"red\", \"orange\", \"violet\"])\n",
        "st.write(\"My favorite color is\", color)\n",
        "\n",
        "if st.button(\"Say hello\"):\n",
        "    st.write(\"Hello\")\n",
        "else:\n",
        "    st.write(\"Goodbye\")\n",
        "\n",
        "st.link_button(\n",
        "    \"Go to Google\",\n",
        "    \"https://www.google.com.vn/\")\n",
        "\n",
        "number = st.number_input(\"Insert a number\")\n",
        "st.write(\"The current number is \", number)\n",
        "\n",
        "values = st.slider(\n",
        "    \"Select a range of values\",\n",
        "    0.0, 100.0, (25.0, 75.0))\n",
        "st.write(\"Values:\", values)\n",
        "\n",
        "# File uploader\n",
        "st.divider()\n",
        "\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Choose files\", accept_multiple_files=True)\n",
        "for uploaded_file in uploaded_files:\n",
        "    bytes_data = uploaded_file.read()\n",
        "    st.write(\"filename:\", uploaded_file.name)\\\n",
        "\n",
        "# Create a form that batches elements together with a \"Submit\" button\n",
        "st.divider()\n",
        "\n",
        "with st.form(\"my_form\"):\n",
        "    col1, col2 = st.columns(2)\n",
        "    f_name = col1.text_input('First Name')\n",
        "    l_name = col2.text_input('Last Name')\n",
        "    submitted = st.form_submit_button(\"Submit\")\n",
        "    if submitted:\n",
        "        st.write(\"First Name: \", f_name, \" - Last Name:\", l_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap8riumLSVxK"
      },
      "source": [
        "##Run the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO2lG5GzKMpo",
        "outputId": "904fcb5c-3062-43fc-d42c-da578b7231f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.219.210:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0Kyour url is: https://early-pillows-pick.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv73mMcvQljz"
      },
      "source": [
        "#Spelling correction using Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9tqRX4ESPF4",
        "outputId": "b1fe02f0-b66b-42b4-f743-c3a755934121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/282.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q spacy contextualSpellCheck==0.4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0llFI1ySuUQ",
        "outputId": "e47b9820-a1d0-42fc-91e6-0d6eec98e99e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting spell_correct.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile spell_correct.py\n",
        "import streamlit as st\n",
        "import spacy\n",
        "import contextualSpellCheck\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "contextualSpellCheck.add_to_pipe(nlp)\n",
        "\n",
        "def spell_correct(text):\n",
        "  doc = nlp(text)\n",
        "  return doc._.performed_spellCheck,  doc._.outcome_spellCheck\n",
        "\n",
        "def main():\n",
        "  st.title('Spelling Correction')\n",
        "  col1, col2, col3 = st.columns([1, 3, 1])\n",
        "\n",
        "  col1.write(\"Enter your text:\")\n",
        "\n",
        "  text = col2.text_input('', 'I go to slaep.', label_visibility=\"collapsed\")\n",
        "\n",
        "  if col3.button('Submit'):\n",
        "    result = spell_correct(text)\n",
        "    if result[0]:\n",
        "        st.success(f'Your text is incorrect! Corrected: {result[1]}')\n",
        "    else:\n",
        "        st.success('Your text is correct!')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAYi5AKOT3mM",
        "outputId": "f86e9a0d-4439-4e42-e4d8-92c6ca56e497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.219.210:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0Kyour url is: https://plain-signs-melt.loca.lt\n",
            "2025-01-04 08:43:19.767234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-04 08:43:19.801846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-04 08:43:19.811747: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-04 08:43:19.835530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-04 08:43:21.460517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-01-04 08:43:22.590 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-01-04 08:43:23.353 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-01-04 08:43:36.931 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-01-04 08:43:44.038 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-01-04 08:44:05.503 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-01-04 08:44:12.748 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run spell_correct.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUYBSaZsfYmU"
      },
      "source": [
        "#Sentiment Analysis using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Zf8S3Wfgda",
        "outputId": "f59d54cf-d707-4d98-c690-43866d4dd92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting sentiment.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sentiment.py\n",
        "import streamlit as st\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def main():\n",
        "  st.title('Sentiment Analysis')\n",
        "  col1, col2, col3 = st.columns([1, 3, 1])\n",
        "\n",
        "  col1.write(\"Enter your text:\")\n",
        "\n",
        "  text = col2.text_input('', 'I dont like you', label_visibility=\"collapsed\")\n",
        "\n",
        "  if col3.button('Submit'):\n",
        "    sentiment = sid.polarity_scores(text)\n",
        "    threshold = 0.1\n",
        "    if sentiment['compound'] >= threshold:\n",
        "      st.success(\"Sentiment: Positive\")\n",
        "    elif sentiment['compound'] <= -threshold:\n",
        "        st.success(\"Sentiment: Negative\")\n",
        "    else:\n",
        "        st.success(\"Sentiment: Neutral\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAVZ0pDDh0l3",
        "outputId": "5a9b893a-6816-4a98-8fd2-b73b750524fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.219.210:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0Kyour url is: https://dry-times-eat.loca.lt\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "2025-01-04 09:05:50.242 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "2025-01-04 09:06:14.125 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "2025-01-04 09:06:21.113 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "2025-01-04 09:06:21.525 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "2025-01-04 09:06:37.562 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run sentiment.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Fb5YfRlkrf"
      },
      "source": [
        "#Translate English to Vietnamese using HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwol8gJ8loJf",
        "outputId": "d47aaedc-a65d-408e-af84-3e264f0ed2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.47.1 in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.47.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.47.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.47.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.47.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.47.1) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.47.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BemoqeDtlpxi",
        "outputId": "91d5ae64-7e44-47e7-a042-d4a6f570004b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting en_to_vi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile en_to_vi.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "#Setup device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Load model\n",
        "model_name = \"thainq107/t5-small-en-vi\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "def translate(text, tokenizer, model):\n",
        "  tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "  output_ids = model.generate(tokenized_text, max_length=128)\n",
        "  translation = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "  return translation\n",
        "\n",
        "def main():\n",
        "  name_device = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n",
        "  st.title(f'Translate English to Vietnamese ({name_device})')\n",
        "  col1, col2, col3 = st.columns([1, 3, 1])\n",
        "\n",
        "  col1.write(\"Enter your text:\")\n",
        "\n",
        "  text = col2.text_input('', 'I dont like you', label_visibility=\"collapsed\")\n",
        "\n",
        "  if col3.button('Submit'):\n",
        "    translation = translate(text, tokenizer, model)\n",
        "    st.success(f'Translation: {translation}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtYHbr9kmXID",
        "outputId": "8769bacb-8992-4e3b-b110-f3dbdff2044e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.35.179:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0Kyour url is: https://soft-bobcats-guess.loca.lt\n",
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "2025-01-04 09:39:06.689514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-04 09:39:06.708152: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-04 09:39:06.713071: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-04 09:39:06.726287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-04 09:39:08.113698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-01-04 09:39:13.951 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-01-04 09:39:14.520 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "2025-01-04 09:39:30.879 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-01-04 09:40:00.254 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run en_to_vi.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVmm7Hmxk/dB5RXYtMKrAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
